{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix shows example\n",
    "\n",
    "https://www.kaggle.com/shivamb/netflix-shows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find out where the pyspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.13-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release"
     ]
    }
   ],
   "source": [
    "# Creating Spark Context\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local[4]\", \"netflix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/pyspark-import-any-data-f2856cda45fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- show_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- cast: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- date_added: string (nullable = true)\n",
      " |-- release_year: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- listed_in: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"netflix_titles.csv\", header =True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- show_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- cast: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- date_added: string (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- listed_in: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"show_id\", StringType()),\n",
    "    StructField(\"type\", StringType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"director\", StringType()),\n",
    "    StructField(\"cast\", StringType()),\n",
    "    StructField(\"country\", StringType()),\n",
    "    StructField(\"date_added\", StringType()),\n",
    "    StructField(\"release_year\", IntegerType()),\n",
    "    StructField(\"rating\", StringType()),\n",
    "    StructField(\"duration\", StringType()),\n",
    "    StructField(\"listed_in\", StringType()),\n",
    "    StructField(\"description\", StringType())])\n",
    "df = spark.read.csv(\"netflix_titles.csv\", header = 'true', schema=schema)\n",
    "df.printSchema()\n",
    "#df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 6236\n"
     ]
    }
   ],
   "source": [
    "print(\"Count: %d\" % df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "| show_id|       date_added|\n",
      "+--------+-----------------+\n",
      "|81145628|September 9, 2019|\n",
      "|80117401|September 9, 2016|\n",
      "|70234439|September 8, 2018|\n",
      "|80058654|September 8, 2018|\n",
      "|80125979|September 8, 2017|\n",
      "+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"show_id\", \"date_added\"]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+----------------+\n",
      "| show_id|       date_added|   date_added_v2|\n",
      "+--------+-----------------+----------------+\n",
      "|81145628|September 9, 2019|September 9 2019|\n",
      "|80117401|September 9, 2016|September 9 2016|\n",
      "|70234439|September 8, 2018|September 8 2018|\n",
      "|80058654|September 8, 2018|September 8 2018|\n",
      "|80125979|September 8, 2017|September 8 2017|\n",
      "+--------+-----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+-----------------+----------------+----------+\n",
      "| show_id|       date_added|   date_added_v2| show_date|\n",
      "+--------+-----------------+----------------+----------+\n",
      "|81145628|September 9, 2019|September 9 2019|2019-09-09|\n",
      "|80117401|September 9, 2016|September 9 2016|2016-09-09|\n",
      "|70234439|September 8, 2018|September 8 2018|2018-09-08|\n",
      "|80058654|September 8, 2018|September 8 2018|2018-09-08|\n",
      "|80125979|September 8, 2017|September 8 2017|2017-09-08|\n",
      "+--------+-----------------+----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark 3 changed date format https://kb.databricks.com/en_US/sql/using-datetime-values-in-spark-30-and-above\n",
    "# We apply some conversion first\n",
    "from pyspark.sql import functions as F\n",
    "df_new = df.withColumn(\"date_added_v2\", F.translate(df['date_added'], \",\", \"\"))\n",
    "df_new.select(['show_id', 'date_added', 'date_added_v2']).show(5)\n",
    "\n",
    "df2 = df_new.withColumn(\"show_date\",F.expr(\"to_date(date_added_v2, 'MMMM d y')\"))\n",
    "df2.select(['show_id', 'date_added', 'date_added_v2', 'show_date']).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyspark.sql.functions as F\n",
    "#\n",
    "#\n",
    "#df2 = df.withColumn(\"show_date\",F.expr(\"to_date('September 12, 2005', 'MMMM dd, yyyy')\"))\n",
    "#df2 = df.withColumn(\"show_date\",F.expr(\"to_date(date_added, 'MMMM dd, yyyy')\"))\n",
    "#\n",
    "#df2.select([\"show_id\", \"date_added\", \"show_date\"]).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+----------+\n",
      "| show_id|       date_added| show_date|\n",
      "+--------+-----------------+----------+\n",
      "|81145628|September 9, 2019|2019-09-09|\n",
      "|80117401|September 9, 2016|2016-09-09|\n",
      "|70234439|September 8, 2018|2018-09-08|\n",
      "|80058654|September 8, 2018|2018-09-08|\n",
      "|80125979|September 8, 2017|2017-09-08|\n",
      "+--------+-----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select([\"show_id\", \"date_added\", \"show_date\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------+\n",
      "| show_id|               title| show_date|\n",
      "+--------+--------------------+----------+\n",
      "|70234439|  Transformers Prime|2018-09-08|\n",
      "|80058654|Transformers: Rob...|2018-09-08|\n",
      "|80244601|     Castle of Stars|2018-09-07|\n",
      "|80203094|         City of Joy|2018-09-07|\n",
      "|80190843|      First and Last|2018-09-07|\n",
      "+--------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dates = (\"2018-01-01\",  \"2018-12-12\")\n",
    "date_from, date_to = [F.to_date(F.lit(s)).cast(TimestampType()) for s in dates]\n",
    "\n",
    "df2.where((df2.show_date > date_from) & (df2.show_date < date_to)).select(\"show_id\", \"title\", \"show_date\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             country|\n",
      "+--------------------+\n",
      "|                null|\n",
      "|     Ama K. Abebrese|\n",
      "|         Aziz Ansari|\n",
      "|       Dominic Costa|\n",
      "|          Doug Plaut|\n",
      "| Justin \"\"Alyssa ...|\n",
      "|  Lachion Buckingham|\n",
      "|          Rob Morgan|\n",
      "|                1944|\n",
      "|           Argentina|\n",
      "|Argentina, Brazil...|\n",
      "|    Argentina, Chile|\n",
      "|Argentina, Chile,...|\n",
      "|   Argentina, France|\n",
      "|Argentina, France...|\n",
      "|    Argentina, Italy|\n",
      "|    Argentina, Spain|\n",
      "|Argentina, United...|\n",
      "|Argentina, United...|\n",
      "|Argentina, Urugua...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"country\").distinct().sort(F.asc(\"country\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.where(F.col(\"country\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.where(F.col(\"country\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5758"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             country|\n",
      "+--------------------+\n",
      "|     Ama K. Abebrese|\n",
      "|         Aziz Ansari|\n",
      "|       Dominic Costa|\n",
      "|          Doug Plaut|\n",
      "| Justin \"\"Alyssa ...|\n",
      "|  Lachion Buckingham|\n",
      "|          Rob Morgan|\n",
      "|                1944|\n",
      "|           Argentina|\n",
      "|Argentina, Brazil...|\n",
      "|    Argentina, Chile|\n",
      "|Argentina, Chile,...|\n",
      "|   Argentina, France|\n",
      "|Argentina, France...|\n",
      "|    Argentina, Italy|\n",
      "|    Argentina, Spain|\n",
      "|Argentina, United...|\n",
      "|Argentina, United...|\n",
      "|Argentina, Urugua...|\n",
      "|Argentina, Urugua...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.select(\"country\").distinct().sort(F.asc(\"country\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_col = F.split(df['country'], ',')\n",
    "df4 = df3.withColumn('main_country', split_col.getItem(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|             country|  main_country|\n",
      "+--------------------+--------------+\n",
      "|United States, In...| United States|\n",
      "|      United Kingdom|United Kingdom|\n",
      "|       United States| United States|\n",
      "|       United States| United States|\n",
      "|       United States| United States|\n",
      "+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.select(\"country\", \"main_country\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        main_country|\n",
      "+--------------------+\n",
      "|     Ama K. Abebrese|\n",
      "|         Aziz Ansari|\n",
      "|       Dominic Costa|\n",
      "|          Doug Plaut|\n",
      "| Justin \"\"Alyssa ...|\n",
      "|  Lachion Buckingham|\n",
      "|          Rob Morgan|\n",
      "|                1944|\n",
      "|           Argentina|\n",
      "|           Australia|\n",
      "|             Austria|\n",
      "|          Bangladesh|\n",
      "|             Belgium|\n",
      "|              Brazil|\n",
      "|            Bulgaria|\n",
      "|            Cambodia|\n",
      "|              Canada|\n",
      "|               Chile|\n",
      "|               China|\n",
      "|            Colombia|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 80)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.select(\"main_country\").distinct().sort(F.asc(\"main_country\")).show(), df4.select(\"main_country\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.select(\"main_country\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|  main_country|count|\n",
      "+--------------+-----+\n",
      "| United States| 2294|\n",
      "|         India|  808|\n",
      "|United Kingdom|  483|\n",
      "|        Canada|  206|\n",
      "|         Japan|  184|\n",
      "|        France|  147|\n",
      "|   South Korea|  146|\n",
      "|         Spain|  139|\n",
      "|        Mexico|   99|\n",
      "|     Australia|   94|\n",
      "|        Turkey|   83|\n",
      "|         China|   77|\n",
      "|     Hong Kong|   73|\n",
      "|        Taiwan|   71|\n",
      "|       Germany|   65|\n",
      "|        Brazil|   57|\n",
      "|     Argentina|   56|\n",
      "|      Thailand|   53|\n",
      "|         Egypt|   52|\n",
      "|     Indonesia|   48|\n",
      "|   Philippines|   46|\n",
      "|         Italy|   40|\n",
      "|       Nigeria|   36|\n",
      "|      Colombia|   29|\n",
      "|       Denmark|   28|\n",
      "|       Ireland|   22|\n",
      "|      Pakistan|   21|\n",
      "|        Israel|   20|\n",
      "|     Singapore|   19|\n",
      "|   Netherlands|   19|\n",
      "+--------------+-----+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.groupby(\"main_country\").count().sort(F.desc(\"count\")).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|         type|\n",
      "+-------------+\n",
      "|      TV Show|\n",
      "|        Movie|\n",
      "|William Wyler|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.select(\"type\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+\n",
      "|release_year|num_types|\n",
      "+------------+---------+\n",
      "|        2018|      953|\n",
      "|        2017|      899|\n",
      "|        2016|      765|\n",
      "|        2019|      725|\n",
      "|        2015|      478|\n",
      "|        2014|      272|\n",
      "|        2013|      225|\n",
      "|        2012|      170|\n",
      "|        2010|      138|\n",
      "|        2011|      133|\n",
      "|        2009|      114|\n",
      "|        2008|      103|\n",
      "|        2007|       68|\n",
      "|        2006|       68|\n",
      "|        2005|       62|\n",
      "|        2004|       48|\n",
      "|        2003|       41|\n",
      "|        2002|       38|\n",
      "|        2001|       33|\n",
      "|        1997|       31|\n",
      "+------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.groupby(\"release_year\").agg(F.count(\"type\").alias(\"num_types\")).sort(F.col(\"num_types\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    " movies = df4.createOrReplaceTempView(\"movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+\n",
      "|release_year|num_types|\n",
      "+------------+---------+\n",
      "|        2018|      953|\n",
      "|        2017|      899|\n",
      "|        2016|      765|\n",
      "|        2019|      725|\n",
      "|        2015|      478|\n",
      "|        2014|      272|\n",
      "|        2013|      225|\n",
      "|        2012|      170|\n",
      "|        2010|      138|\n",
      "|        2011|      133|\n",
      "|        2009|      114|\n",
      "|        2008|      103|\n",
      "|        2007|       68|\n",
      "|        2006|       68|\n",
      "|        2005|       62|\n",
      "|        2004|       48|\n",
      "|        2003|       41|\n",
      "|        2002|       38|\n",
      "|        2001|       33|\n",
      "|        1997|       31|\n",
      "+------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select                \n",
    "release_year,\n",
    "count(type) AS num_types\n",
    "from movies\n",
    "GROUP BY release_year\n",
    "ORDER BY num_types  DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
